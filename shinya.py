import streamlit as st
import requests
import sqlite3
import gzip
import shutil
import os
import html
import urllib.parse  # è¿½åŠ ï¼šURLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾ç­–

DB_GZ_URL = "https://github.com/22552/kasosuta-dataset/releases/download/dai2v1/cmt.db.gz"
DB_FILE = "comments.db"
GZ_FILE = "cmt.db.gz"

# =========================
# DBæº–å‚™
# =========================
def ensure_db():
    if os.path.exists(DB_FILE):
        return

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if not os.path.exists(GZ_FILE):
        r = requests.get(DB_GZ_URL, stream=True, timeout=120)
        r.raise_for_status()
        with open(GZ_FILE, "wb") as f:
            for chunk in r.iter_content(8192):
                f.write(chunk)

    # å±•é–‹
    with gzip.open(GZ_FILE, "rb") as f_in:
        with open(DB_FILE, "wb") as f_out:
            shutil.copyfileobj(f_in, f_out)

ensure_db()

# =========================
# SQLiteæ¥ç¶š
# =========================
conn = sqlite3.connect(DB_FILE, check_same_thread=False)
cur = conn.cursor()

# =========================
# UI
# =========================
st.title("Scratch ã‚³ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚¢ãƒ—ãƒª")
st.write("å…«æˆ¸å¸‚ã«ã„ã“ã†!")

user_q = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
text_q = st.text_input("å†…å®¹")

if st.button("æ¤œç´¢"):

    query = """
    SELECT id,user,datetime,content,is_reply,parent_id
    FROM comments
    WHERE 1=1
    """

    params = []

    if user_q:
        query += " AND user LIKE ?"
        params.append(f"%{user_q}%")

    if text_q:
        # --- æ¤œç´¢å¼·åŒ–ãƒ­ã‚¸ãƒƒã‚¯ ---
        # 1. é€šå¸¸ã®å…¥åŠ›
        # 2. HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ— ( > -> &gt; ãªã©)
        # 3. URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (çµµæ–‡å­—ã‚„ç‰¹æ®Šè¨˜å·å¯¾ç­–)
        
        escaped_q = html.escape(text_q)
        url_encoded_q = urllib.parse.quote(text_q)
        
        # ORæ¡ä»¶ã§ã€ã„ãšã‚Œã‹ã®å½¢å¼ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚Œã°ãƒ’ãƒƒãƒˆã™ã‚‹ã‚ˆã†ã«ã™ã‚‹
        query += " AND (content LIKE ? OR content LIKE ? OR content LIKE ?)"
        params.append(f"%{text_q}%")      # ãã®ã¾ã¾
        params.append(f"%{escaped_q}%")  # &gt; ãªã©
        params.append(f"%{url_encoded_q}%") # %F0%9F... ãªã©
        # -----------------------

    # ğŸ”¥ è¦ª â†’ è¿”ä¿¡ ã®é †ã«ãªã‚‹ä¸¦ã³
    query += """
ORDER BY
    COALESCE(parent_id, id) DESC,
    datetime ASC
    """

    rows = cur.execute(query, params).fetchall()

    st.session_state["rows"] = rows
    st.session_state["page"] = 1

# =========================
# ãƒšãƒ¼ã‚¸è¡¨ç¤º
# =========================
if "rows" in st.session_state:

    rows = st.session_state["rows"]

    page_size = 200
    total_pages = max(1, (len(rows) + page_size - 1) // page_size)

    page = st.number_input(
        "ãƒšãƒ¼ã‚¸",
        min_value=1,
        max_value=total_pages,
        value=st.session_state.get("page", 1),
        key="page_input"
    )

    start = (page - 1) * page_size
    end = start + page_size

    st.write(f"è¡¨ç¤ºä¸­: {start+1} - {min(end, len(rows))} / {len(rows)}")

    for r in rows[start:end]:
        prefix = "â†³ " if r[4] == 1 else ""
        parent = f"(è¿”ä¿¡å…ˆ: {r[5]})" if r[4] == 1 else ""
        
        # è¡¨ç¤ºæ™‚ã¯äººé–“ãŒèª­ã¿ã‚„ã™ã„ã‚ˆã†ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆæˆ»ã™ï¼‰ã—ã¦è¡¨ç¤º
        # â€»HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã®ä¸¡æ–¹ã‚’è§£é™¤
        display_content = html.unescape(r[3])
        try:
            display_content = urllib.parse.unquote(display_content)
        except:
            pass
            
        st.write(f"{prefix}ID:{r[0]} [{r[2]}] {r[1]}: {display_content} {parent}")
